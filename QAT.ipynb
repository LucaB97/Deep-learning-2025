{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.ao.quantization as quant\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bits=8):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.bits = bits\n",
    "\n",
    "        # Define standard linear layer\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "        # Register fake quantization for QAT (Quantization-Aware Training)\n",
    "        self.weight_fake_quant = quant.fake_quantize.FusedMovingAvgObsFakeQuantize(\n",
    "            observer=quant.observer.MovingAverageMinMaxObserver, quant_min=-128, quant_max=127, dtype=torch.qint8\n",
    "        )\n",
    "\n",
    "        self.activation_fake_quant = quant.fake_quantize.FusedMovingAvgObsFakeQuantize(\n",
    "            observer=quant.observer.MovingAverageMinMaxObserver, quant_min=0, quant_max=255, dtype=torch.quint8\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            # Apply quantization-aware training (QAT)\n",
    "            w_q = self.weight_fake_quant(self.linear.weight)\n",
    "            x_q = self.activation_fake_quant(x)\n",
    "            return F.linear(x_q, w_q, self.linear.bias)\n",
    "        else:\n",
    "            # Use pre-quantized inference mode (static quantization)\n",
    "            return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, head_size, block_size, quantization_bits=8, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.key = BitLinear(n_embd, head_size, quantization_bits)\n",
    "        self.query = BitLinear(n_embd, head_size, quantization_bits)\n",
    "        self.value = BitLinear(n_embd, head_size, quantization_bits)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"head forwarding\")\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * self.head_size **-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "    \n",
    "\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "  def __init__(self, num_heads, n_embd, head_size, block_size, quantization_bits=8, dropout=0.2):\n",
    "    super().__init__()\n",
    "    self.heads = nn.ModuleList([Head(n_embd, head_size, block_size, quantization_bits) for _ in range(num_heads)])\n",
    "    self.proj = BitLinear(n_embd, n_embd, quantization_bits)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self,x):\n",
    "    # print(\"sa forwarding\")\n",
    "    out = torch.cat([h(x) for h in self.heads], dim = -1) #concat over channel dim\n",
    "    # print(\"now proj\")\n",
    "    out = self.proj(out)\n",
    "    return out\n",
    "  \n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "\n",
    "  def __init__(self, n_embd, quantization_bits=8, dropout=0.2):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        BitLinear(n_embd, 4*n_embd, quantization_bits), # *4 secondo argomento\n",
    "        nn.ReLU(),\n",
    "        BitLinear(4*n_embd, n_embd, quantization_bits), #proj layer #*4 primo argomento\n",
    "        nn.Dropout(dropout),\n",
    "    )\n",
    "\n",
    "  def forward(self,x):\n",
    "    # print(\"ffwd forwarding\")\n",
    "    return self.net(x)\n",
    "  \n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "  def __init__(self, num_heads, n_embd, block_size, sa_bits=8, ffwd_bits=8):\n",
    "    super().__init__()\n",
    "    head_size = n_embd//num_heads\n",
    "    self.sa = MultiHeadAttention(num_heads, n_embd, head_size, block_size, sa_bits)\n",
    "    self.ffwd = FeedForward(n_embd, quantization_bits=ffwd_bits)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = x + self.sa(x)\n",
    "    x = x + self.ffwd(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, num_layers, num_heads, n_embd, block_size=8, bits=8):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        \n",
    "        self.blocks = nn.Sequential(*[Block(num_heads, n_embd, block_size, sa_bits=bits, ffwd_bits=bits) for _ in range(num_layers)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.linear = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # Apply quantization stubs\n",
    "        self.quant = quant.QuantStub()\n",
    "        self.dequant = quant.DeQuantStub()\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=idx.device))\n",
    "        x = tok_emb + pos_emb\n",
    "\n",
    "        if not self.training:\n",
    "            x = self.quant(x)  # Apply quantization before passing through layers\n",
    "\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.linear(x)\n",
    "\n",
    "        if not self.training:\n",
    "            logits = self.dequant(logits)  # Dequantize before returning output\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            logits = logits.reshape(B * T, logits.size(-1))\n",
    "            targets = targets.reshape(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "    def prepare_for_quantization(self):\n",
    "        \"\"\"Prepare the model for quantization-aware training (QAT).\"\"\"\n",
    "        self.train()\n",
    "\n",
    "        # Standard quantization config for all layers *except* Embedding\n",
    "        self.qconfig = quant.qconfig_mapping.get_default_qat_qconfig(\"fbgemm\")\n",
    "\n",
    "        # Prevent Embedding layers from being quantized\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Embedding):\n",
    "                module.qconfig = None  # Exclude Embeddings from quantization\n",
    "\n",
    "        quant.prepare_qat(self, inplace=True)\n",
    "\n",
    "\n",
    "    def convert_to_quantized(self):\n",
    "        \"\"\"Convert model to fully quantized version for fast inference.\"\"\"\n",
    "        # self.eval()\n",
    "        # Create a mapping that excludes Embedding layers\n",
    "        mapping = {nn.Linear: torch.ao.nn.quantized.Linear}  # Only quantize Linear layers\n",
    "        quant.convert(self, mapping=mapping, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "efficient QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def efficientQAT(model, data_loader, optimizer_block, optimizer_e2e):\n",
    "def QAT(model, data_loader, optimizer_block):\n",
    "    \"\"\"    \n",
    "    Parameters:\n",
    "    - model: The quantized model.\n",
    "    - data_loader: The data loader to provide input batches.\n",
    "    - optimizer_block: Optimizer for block training.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    model.prepare_for_quantization()  # Enable QAT\n",
    "    \n",
    "    for _, (inputs, targets) in enumerate(data_loader):\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        optimizer_block.zero_grad()\n",
    "        _, loss = model(inputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_block.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data load, encoding, training & test set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split, train_data, val_data, block_size, batch_size):\n",
    "    \n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model, train_data, val_data, block_size, batch_size, eval_iters=200):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    model.convert_to_quantized()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, train_data, val_data, block_size, batch_size)\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model, train_data, val_data, block_size, batch_size, eval_iters=200):\n",
    "    out = {}\n",
    "    # model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Create a copy and convert it to quantized\n",
    "    qmodel = copy.deepcopy(model)\n",
    "    qmodel.eval()\n",
    "    qmodel.convert_to_quantized()\n",
    "\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, train_data, val_data, block_size, batch_size)\n",
    "            _, loss = qmodel(X, Y)  # Use quantized model for inference\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "\n",
    "    # model.train()  # Restore training mode for original model\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt','r', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32\n",
    "block_size = 8\n",
    "n_embd = 32\n",
    "n_head = 4\n",
    "n_layer = 6\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "epoch_length = 200\n",
    "eval_iters = 200\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning at: train loss 4.3150, val loss 4.3141\n",
      "\n",
      "step 0: train loss 2.6291, val loss 2.6160\n",
      "step 1: train loss 2.4518, val loss 2.4675\n",
      "step 2: train loss 2.3832, val loss 2.3946\n",
      "step 3: train loss 2.3164, val loss 2.3274\n",
      "step 4: train loss 2.2774, val loss 2.2902\n",
      "step 5: train loss 2.2510, val loss 2.2603\n",
      "step 6: train loss 2.2276, val loss 2.2401\n",
      "step 7: train loss 2.2049, val loss 2.2171\n",
      "step 8: train loss 2.1815, val loss 2.2120\n",
      "step 9: train loss 2.1568, val loss 2.1956\n",
      "676.4785394668579\n"
     ]
    }
   ],
   "source": [
    "qmodel8 = BigramLanguageModel(vocab_size, n_layer, n_head, n_embd, block_size=8).to(device)\n",
    "\n",
    "initial_loss = estimate_loss(qmodel8, train_data, val_data, block_size, batch_size, eval_iters)\n",
    "print(f\"Beginning at: train loss {initial_loss['train']:.4f}, val loss {initial_loss['val']:.4f}\\n\")\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': [p for name, p in qmodel8.named_parameters()], 'lr': learning_rate}\n",
    "])\n",
    "\n",
    "data_loader = [(get_batch('train', train_data, val_data, block_size, batch_size)) for _ in range(epoch_length)]  # Replace with your DataLoader\n",
    "loss_val8 = []\n",
    "loss_train8 = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    QAT(qmodel8, data_loader, optimizer)\n",
    "    losses = estimate_loss(qmodel8, train_data, val_data, block_size, batch_size, eval_iters)\n",
    "    loss_val8.append(losses['val'])\n",
    "    loss_train8.append(losses['train'])\n",
    "    print(f\"step {epoch}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "total_time = end - start\n",
    "print(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BigramLanguageModel(\n",
       "  (token_embedding_table): Embedding(65, 32)\n",
       "  (position_embedding_table): Embedding(8, 32)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.27910614013671875, max_val=0.2838379442691803)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.26788973808288574, max_val=0.2842845022678375)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24177508056163788, max_val=0.2549028992652893)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28265056014060974, max_val=0.27317631244659424)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28098803758621216, max_val=0.29316604137420654)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.25573310256004333, max_val=0.23531392216682434)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.275408536195755, max_val=0.28454357385635376)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2523666024208069, max_val=0.25415825843811035)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([-6], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.23986764252185822, max_val=0.2607271373271942)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3099725544452667, max_val=0.3167582154273987)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.29546716809272766, max_val=0.2992457151412964)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2716095447540283, max_val=0.2785203456878662)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0377]), zero_point=tensor([140], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.2834367752075195, max_val=4.331521034240723)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): BitLinear(\n",
       "          (linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2642415165901184, max_val=0.26965007185935974)\n",
       "          )\n",
       "          (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0226]), zero_point=tensor([133], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.011032819747925, max_val=2.7526559829711914)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): BitLinear(\n",
       "            (linear): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.313303142786026, max_val=0.32652395963668823)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0398]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.462763786315918, max_val=4.673861026763916)\n",
       "            )\n",
       "          )\n",
       "          (1): ReLU()\n",
       "          (2): BitLinear(\n",
       "            (linear): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2195904701948166, max_val=0.2273010015487671)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0124]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.156456470489502)\n",
       "            )\n",
       "          )\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2815943658351898, max_val=0.30323731899261475)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28180792927742004, max_val=0.2831418812274933)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([8], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.27163568139076233, max_val=0.23798240721225739)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.29092857241630554, max_val=0.3072197139263153)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.27863809466362, max_val=0.28651463985443115)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.26886191964149475, max_val=0.27560168504714966)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([-9], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2799158990383148, max_val=0.3198409378528595)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.29159530997276306, max_val=0.2795693278312683)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24228672683238983, max_val=0.246055468916893)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.27654793858528137, max_val=0.28290998935699463)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.27874892950057983, max_val=0.2895595133304596)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2787903845310211, max_val=0.2589949369430542)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0429]), zero_point=tensor([137], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.869776725769043, max_val=5.0770134925842285)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): BitLinear(\n",
       "          (linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.26996511220932007, max_val=0.2765079140663147)\n",
       "          )\n",
       "          (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0257]), zero_point=tensor([134], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4350290298461914, max_val=3.108853578567505)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): BitLinear(\n",
       "            (linear): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.333678662776947, max_val=0.3212772607803345)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0469]), zero_point=tensor([135], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.351231575012207, max_val=5.610592365264893)\n",
       "            )\n",
       "          )\n",
       "          (1): ReLU()\n",
       "          (2): BitLinear(\n",
       "            (linear): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.22463998198509216, max_val=0.23436099290847778)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0146]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.725125551223755)\n",
       "            )\n",
       "          )\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2727067172527313, max_val=0.2694980204105377)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2735616862773895, max_val=0.2596033811569214)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.26158854365348816, max_val=0.24351947009563446)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2688695192337036, max_val=0.28879836201667786)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.28560057282447815, max_val=0.28466546535491943)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.25713232159614563, max_val=0.24227242171764374)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2758914530277252, max_val=0.2823507487773895)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2670256495475769, max_val=0.2770116627216339)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.26316651701927185, max_val=0.22312302887439728)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.27747777104377747, max_val=0.2907690405845642)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0023]), zero_point=tensor([3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2952740490436554, max_val=0.2798762321472168)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24961704015731812, max_val=0.24046872556209564)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0529]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.851916790008545, max_val=6.630074501037598)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): BitLinear(\n",
       "          (linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2827455699443817, max_val=0.25261190533638)\n",
       "          )\n",
       "          (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0314]), zero_point=tensor([121], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.8011181354522705, max_val=4.206931114196777)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): BitLinear(\n",
       "            (linear): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3060950040817261, max_val=0.3111414909362793)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0563]), zero_point=tensor([128], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.228322982788086, max_val=7.1190714836120605)\n",
       "            )\n",
       "          )\n",
       "          (1): ReLU()\n",
       "          (2): BitLinear(\n",
       "            (linear): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24269047379493713, max_val=0.2260563224554062)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0205]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=5.225769519805908)\n",
       "            )\n",
       "          )\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([6], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2942203879356384, max_val=0.2650372385978699)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2725345194339752, max_val=0.28081971406936646)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2506753206253052, max_val=0.23058012127876282)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([-4], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.25064706802368164, max_val=0.26492664217948914)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2607463002204895, max_val=0.26613160967826843)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.27980872988700867, max_val=0.23601983487606049)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2614555358886719, max_val=0.27114295959472656)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2737119793891907, max_val=0.28046441078186035)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2642853558063507, max_val=0.2947161793708801)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2535198926925659, max_val=0.272686243057251)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2872210144996643, max_val=0.27329781651496887)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2477465718984604, max_val=0.21940231323242188)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0625]), zero_point=tensor([130], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.114316940307617, max_val=7.810995101928711)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): BitLinear(\n",
       "          (linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2639605700969696, max_val=0.268338143825531)\n",
       "          )\n",
       "          (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0409]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.144416332244873, max_val=5.2855730056762695)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): BitLinear(\n",
       "            (linear): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0025]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3090795576572418, max_val=0.31674426794052124)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0705]), zero_point=tensor([134], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.467885971069336, max_val=8.517006874084473)\n",
       "            )\n",
       "          )\n",
       "          (1): ReLU()\n",
       "          (2): BitLinear(\n",
       "            (linear): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.22542017698287964, max_val=0.2289341390132904)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0236]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=6.016557693481445)\n",
       "            )\n",
       "          )\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24621137976646423, max_val=0.2746967375278473)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([-13], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.21957844495773315, max_val=0.2675868272781372)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([-10], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.21152789890766144, max_val=0.24418053030967712)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2669600248336792, max_val=0.2628211975097656)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([-9], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.22739875316619873, max_val=0.2601448893547058)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-9], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24773655831813812, max_val=0.28147661685943604)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.254069447517395, max_val=0.25584957003593445)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.23008102178573608, max_val=0.25654861330986023)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([12], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2824300527572632, max_val=0.23233146965503693)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([-9], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.23879481852054596, max_val=0.2712878882884979)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24469077587127686, max_val=0.26237952709198)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24303942918777466, max_val=0.23921248316764832)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0794]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.38401985168457, max_val=9.865262031555176)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): BitLinear(\n",
       "          (linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-2], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.26502910256385803, max_val=0.27112045884132385)\n",
       "          )\n",
       "          (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0472]), zero_point=tensor([131], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.170666694641113, max_val=5.855947494506836)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): BitLinear(\n",
       "            (linear): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0024]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.30146944522857666, max_val=0.3223334848880768)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0833]), zero_point=tensor([127], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.582895278930664, max_val=10.670562744140625)\n",
       "            )\n",
       "          )\n",
       "          (1): ReLU()\n",
       "          (2): BitLinear(\n",
       "            (linear): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([-1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.22774344682693481, max_val=0.22922742366790771)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0286]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=7.302256107330322)\n",
       "            )\n",
       "          )\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24235710501670837, max_val=0.250919908285141)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([-9], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.23856310546398163, max_val=0.27381351590156555)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2759586274623871, max_val=0.24354593455791473)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([-8], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.232151061296463, max_val=0.25958251953125)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.23759809136390686, max_val=0.23106175661087036)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24756985902786255, max_val=0.2255999594926834)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0021]), zero_point=tensor([-7], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.24952949583530426, max_val=0.27498409152030945)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0022]), zero_point=tensor([1], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.2875621020793915, max_val=0.2811368405818939)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([-6], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.22568368911743164, max_val=0.24563561379909515)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.26878082752227783, max_val=0.24652531743049622)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (query): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0020]), zero_point=tensor([-3], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.25628626346588135, max_val=0.2662172019481659)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (value): BitLinear(\n",
       "              (linear): Linear(in_features=32, out_features=8, bias=True)\n",
       "              (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([13], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.25328388810157776, max_val=0.2034648060798645)\n",
       "              )\n",
       "              (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "                fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0917]), zero_point=tensor([126], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.512882232666016, max_val=11.871304512023926)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): BitLinear(\n",
       "          (linear): Linear(in_features=32, out_features=32, bias=True)\n",
       "          (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0019]), zero_point=tensor([-11], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.22152367234230042, max_val=0.26038336753845215)\n",
       "          )\n",
       "          (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "            fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0546]), zero_point=tensor([125], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.819718837738037, max_val=7.11596155166626)\n",
       "          )\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): BitLinear(\n",
       "            (linear): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0026]), zero_point=tensor([-5], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31886041164398193, max_val=0.3422004282474518)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0990]), zero_point=tensor([129], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-12.7293119430542, max_val=12.505027770996094)\n",
       "            )\n",
       "          )\n",
       "          (1): ReLU()\n",
       "          (2): BitLinear(\n",
       "            (linear): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (weight_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0018]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.qint8, quant_min=-128, quant_max=127, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.23515291512012482, max_val=0.23305568099021912)\n",
       "            )\n",
       "            (activation_fake_quant): FusedMovingAvgObsFakeQuantize(\n",
       "              fake_quant_enabled=tensor([1]), observer_enabled=tensor([1]), scale=tensor([0.0335]), zero_point=tensor([0], dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine, reduce_range=False\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=8.546209335327148)\n",
       "            )\n",
       "          )\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (linear): Linear(in_features=32, out_features=65, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmodel8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning at: train loss 4.3689, val loss 4.3841\n",
      "\n",
      "step 0: train loss 2.6279, val loss 2.6407\n",
      "step 1: train loss 2.4489, val loss 2.4643\n",
      "step 2: train loss 2.3795, val loss 2.3788\n",
      "step 3: train loss 2.3177, val loss 2.3376\n",
      "step 4: train loss 2.2713, val loss 2.3085\n",
      "step 5: train loss 2.2513, val loss 2.2731\n",
      "step 6: train loss 2.2163, val loss 2.2419\n",
      "step 7: train loss 2.2105, val loss 2.2492\n",
      "step 8: train loss 2.1769, val loss 2.2034\n",
      "step 9: train loss 2.1708, val loss 2.2126\n",
      "645.8131875991821\n"
     ]
    }
   ],
   "source": [
    "qmodel8_2 = BigramLanguageModel(vocab_size, n_layer, n_head, n_embd, block_size=8).to(device)\n",
    "\n",
    "initial_loss_2 = estimate_loss(qmodel8_2, train_data, val_data, block_size, batch_size, eval_iters)\n",
    "print(f\"Beginning at: train loss {initial_loss_2['train']:.4f}, val loss {initial_loss_2['val']:.4f}\\n\")\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': [p for name, p in qmodel8_2.named_parameters()], 'lr': learning_rate}\n",
    "])\n",
    "\n",
    "data_loader = [(get_batch('train', train_data, val_data, block_size, batch_size)) for _ in range(epoch_length)]  # Replace with your DataLoader\n",
    "loss_val8_2 = []\n",
    "loss_train8_2 = []\n",
    "\n",
    "start_2 = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    QAT(qmodel8_2, data_loader, optimizer)\n",
    "    losses_2 = estimate_loss(qmodel8_2, train_data, val_data, block_size, batch_size, eval_iters)\n",
    "    loss_val8_2.append(losses_2['val'])\n",
    "    loss_train8_2.append(losses_2['train'])\n",
    "    print(f\"step {epoch}: train loss {losses_2['train']:.4f}, val loss {losses_2['val']:.4f}\")\n",
    "    \n",
    "\n",
    "end_2 = time.time()\n",
    "total_time_2 = end_2 - start_2\n",
    "print(total_time_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
